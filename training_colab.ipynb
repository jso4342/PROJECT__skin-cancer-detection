{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"training_colab.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO+tj/GcQDt6H3AVTggmPe2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Import Default Packages "],"metadata":{"id":"J3qK5lgzFwj8"}},{"cell_type":"code","execution_count":11,"metadata":{"id":"pjL0FfmdKLeK","executionInfo":{"status":"ok","timestamp":1649622282107,"user_tz":-540,"elapsed":412,"user":{"displayName":"Seoyoung Jang","userId":"05750081912765387034"}}},"outputs":[],"source":["\"\"\"\n","Skin cancer lesion classification using the HAM10000 dataset\n","Dataset link:\n","https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/DBW86T\n","\n","Data description:\n","\n","Actinic keratoses and intraepithelial carcinoma / Bowen's disease (akiec)\n","basal cell carcinoma (bcc)\n","benign keratosis-like lesions (solar lentigines / seborrheic keratoses and lichen-planus like keratoses, bkl)\n","dermatofibroma (df)\n","melanoma (mel)\n","melanocytic nevi (nv) \n","vascular lesions (angiomas, angiokeratomas, pyogenic granulomas and hemorrhage, vasc).\n","\n","GPU - >  a lot faster !! \n","transfer learning with GPU \n","\"\"\"\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import os\n","from glob import glob\n","import seaborn as sns\n","from PIL import Image\n","\n","np.random.seed(42)\n","from keras.utils.np_utils import to_categorical # used for converting labels to one-hot-encoding\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, MaxPool2D\n","from sklearn.model_selection import train_test_split\n","from scipy import stats\n","from sklearn.preprocessing import LabelEncoder"]},{"cell_type":"code","source":["pip install autokeras"],"metadata":{"id":"fzceUR4BDbeA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import autokeras as ak\n","import tensorflow as tf\n","import keras"],"metadata":{"id":"KDxWg5S5DveB","executionInfo":{"status":"ok","timestamp":1649622299603,"user_tz":-540,"elapsed":4,"user":{"displayName":"Seoyoung Jang","userId":"05750081912765387034"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["# Upload and Download File"],"metadata":{"id":"NB6D6FnuGTmZ"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","# have to upload the files on drive \n","# 참고 : https://vision-ai.tistory.com/entry/%EC%BD%94%EB%9E%A9%EC%97%90%EC%84%9C-%EB%93%9C%EB%9D%BC%EC%9D%B4%EB%B8%8C%EC%9D%98-csv-%ED%8C%8C%EC%9D%BC-%EC%9D%BD%EA%B8%B0\n","# 참고 : https://growthj.link/python-%EA%B5%AC%EA%B8%80-colab%EC%9C%BC%EB%A1%9C-pd-read-csv-%ED%99%9C%EC%9A%A9%ED%95%98%EB%8A%94-%EB%B0%A9%EB%B2%95/"],"metadata":{"id":"Rew8Rwl8GT8D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649720145766,"user_tz":-540,"elapsed":24199,"user":{"displayName":"Seoyoung Jang","userId":"05750081912765387034"}},"outputId":"d6c66685-3c0c-4a74-b85c-07728fea3770"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import io\n","#skin_df = pd.read_csv(\"/content/HAM10000_metadata.csv\")\n","skin_df = pd.read_csv(\"/content/drive/MyDrive/Thesis/dataset/HAM10000_metadata\")\n","\n","skin_df.head()"],"metadata":{"id":"DvxK_z0cORaV","colab":{"base_uri":"https://localhost:8080/","height":248},"executionInfo":{"status":"ok","timestamp":1649720227189,"user_tz":-540,"elapsed":1755,"user":{"displayName":"Seoyoung Jang","userId":"05750081912765387034"}},"outputId":"4bad6535-df98-4157-ca9d-3f05ae1dd95e"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["     lesion_id      image_id   dx dx_type   age   sex localization  \\\n","0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp   \n","1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp   \n","2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp   \n","3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp   \n","4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear   \n","\n","        dataset  \n","0  vidir_modern  \n","1  vidir_modern  \n","2  vidir_modern  \n","3  vidir_modern  \n","4  vidir_modern  "],"text/html":["\n","  <div id=\"df-be1a97ed-54b5-4bd8-be02-f984dbc7d0ee\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>lesion_id</th>\n","      <th>image_id</th>\n","      <th>dx</th>\n","      <th>dx_type</th>\n","      <th>age</th>\n","      <th>sex</th>\n","      <th>localization</th>\n","      <th>dataset</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>HAM_0000118</td>\n","      <td>ISIC_0027419</td>\n","      <td>bkl</td>\n","      <td>histo</td>\n","      <td>80.0</td>\n","      <td>male</td>\n","      <td>scalp</td>\n","      <td>vidir_modern</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>HAM_0000118</td>\n","      <td>ISIC_0025030</td>\n","      <td>bkl</td>\n","      <td>histo</td>\n","      <td>80.0</td>\n","      <td>male</td>\n","      <td>scalp</td>\n","      <td>vidir_modern</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>HAM_0002730</td>\n","      <td>ISIC_0026769</td>\n","      <td>bkl</td>\n","      <td>histo</td>\n","      <td>80.0</td>\n","      <td>male</td>\n","      <td>scalp</td>\n","      <td>vidir_modern</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>HAM_0002730</td>\n","      <td>ISIC_0025661</td>\n","      <td>bkl</td>\n","      <td>histo</td>\n","      <td>80.0</td>\n","      <td>male</td>\n","      <td>scalp</td>\n","      <td>vidir_modern</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>HAM_0001466</td>\n","      <td>ISIC_0031633</td>\n","      <td>bkl</td>\n","      <td>histo</td>\n","      <td>75.0</td>\n","      <td>male</td>\n","      <td>ear</td>\n","      <td>vidir_modern</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-be1a97ed-54b5-4bd8-be02-f984dbc7d0ee')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-be1a97ed-54b5-4bd8-be02-f984dbc7d0ee button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-be1a97ed-54b5-4bd8-be02-f984dbc7d0ee');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["# Confirm TensorFlow can see the GPU"],"metadata":{"id":"g0xT9EHQHwLO"}},{"cell_type":"code","source":["device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GUP:0':\n","    print('Found GPU at: {}'.format(device_name))"],"metadata":{"id":"0iy71isSH7sK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649622429101,"user_tz":-540,"elapsed":366,"user":{"displayName":"Seoyoung Jang","userId":"05750081912765387034"}},"outputId":"0a0a05ee-5d92-45f2-c328-dbbc04890c02"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Found GPU at: /device:GPU:0\n"]}]},{"cell_type":"markdown","source":["# Link Colab in jupyter notebook"],"metadata":{"id":"63TAqK2CKUef"}},{"cell_type":"markdown","source":["The direct colab link to this notebook is : https://colab.research.people.com/github/jso4342/Skin-Cancer-Detection.git"],"metadata":{"id":"wrQwM5hxKurq"}},{"cell_type":"code","source":[""],"metadata":{"id":"3R7NT7vTKT7m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#size of pixels that I want to resize the images \n","SIZE = 60\n","\n","\n","# label encoding to numeric values from text\n","le = LabelEncoder()\n","le.fit(skin_df['dx'])\n","LabelEncoder()\n","print(list(le.classes_))\n"," \n","skin_df['label'] = le.transform(skin_df[\"dx\"]) \n","print(skin_df.sample(10))\n","\n","\n","\"\"\"\n","\n","# Data distribution visualization\n","fig = plt.figure(figsize=(15,10))\n","\n","ax1 = fig.add_subplot(221)\n","skin_df['dx'].value_counts().plot(kind='bar', ax=ax1)\n","ax1.set_ylabel('Count')\n","ax1.set_title('Cell Type');\n","\n","ax2 = fig.add_subplot(222)\n","skin_df['sex'].value_counts().plot(kind='bar', ax=ax2)\n","ax2.set_ylabel('Count', size=15)\n","ax2.set_title('Sex');\n","\n","ax3 = fig.add_subplot(223)\n","skin_df['localization'].value_counts().plot(kind='bar')\n","ax3.set_ylabel('Count',size=12)\n","ax3.set_title('Localization')\n","\n","\n","ax4 = fig.add_subplot(224)\n","sample_age = skin_df[pd.notnull(skin_df['age'])]\n","sns.distplot(sample_age['age'], fit=stats.norm, color='red');\n","ax4.set_title('Age')\n","\n","plt.tight_layout()\n","plt.show()\n","\n","\"\"\""],"metadata":{"id":"tQ0RkyBNLlrh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"BX4jYv4RVTh4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Balance data.\n","# Many ways to balance data... you can also try assigning weights during model.fit\n","#Separate each classes, resample, and combine back into single dataframe\n","\n","df_0 = skin_df[skin_df['label'] == 0]\n","df_1 = skin_df[skin_df['label'] == 1]\n","df_2 = skin_df[skin_df['label'] == 2]\n","df_3 = skin_df[skin_df['label'] == 3]\n","df_4 = skin_df[skin_df['label'] == 4]\n","df_5 = skin_df[skin_df['label'] == 5]\n","df_6 = skin_df[skin_df['label'] == 6]\n","\n","n_samples=500 \n","df_0_balanced = resample(df_0, replace=True, n_samples=n_samples, random_state=42) \n","df_1_balanced = resample(df_1, replace=True, n_samples=n_samples, random_state=42) \n","df_2_balanced = resample(df_2, replace=True, n_samples=n_samples, random_state=42)\n","df_3_balanced = resample(df_3, replace=True, n_samples=n_samples, random_state=42)\n","df_4_balanced = resample(df_4, replace=True, n_samples=n_samples, random_state=42)\n","df_5_balanced = resample(df_5, replace=True, n_samples=n_samples, random_state=42)\n","df_6_balanced = resample(df_6, replace=True, n_samples=n_samples, random_state=42)\n","\n","skin_df_balanced = pd.concat([df_0_balanced, df_1_balanced, \n","                              df_2_balanced, df_3_balanced, \n","                              df_4_balanced, df_5_balanced, df_6_balanced])\n"],"metadata":{"id":"sj7A6qHaTY9G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\"\"\"\n","# Distribution of data into various classes \n","from sklearn.utils import resample\n","print(skin_df['label'].value_counts())\n","\n","\n","#Now time to read images based on image ID from the CSV file\n","#This is the safest way to read images as it ensures the right image is read for the right ID\n","print(skin_df_balanced['label'].value_counts())\n","\n","\n","image_path = {os.path.splitext(os.path.basename(x))[0]: x\n","                     for x in glob(os.path.join('data/HAM10000/', '*', '*.jpg'))}\n","#Define the path and add as a new column\n","skin_df_balanced['path'] = skin_df['image_id'].map(image_path.get)\n","#Use the path to read images.\n","skin_df_balanced['image'] = skin_df_balanced['path'].map(lambda x: np.asarray(Image.open(x).resize((SIZE,SIZE))))\n","\n","\n","n_samples = 5  \n","\n","# Plot\n","fig, m_axs = plt.subplots(7, n_samples, figsize = (4*n_samples, 3*7))\n","for n_axs, (type_name, type_rows) in zip(m_axs, \n","                                         skin_df_balanced.sort_values(['dx']).groupby('dx')):\n","    n_axs[0].set_title(type_name)\n","    for c_ax, (_, c_row) in zip(n_axs, type_rows.sample(n_samples, random_state=1234).iterrows()):\n","        c_ax.imshow(c_row['image'])\n","        c_ax.axis('off')\n","\n","\n","#Convert dataframe column of images into numpy array\n","X = np.asarray(skin_df_balanced['image'].tolist())\n","X = X/255. # Scale values to 0-1. You can also used standardscaler or other scaling methods.\n","Y=skin_df_balanced['label'] #Assign label values to Y\n","Y_cat = to_categorical(Y, num_classes=7) #Convert to categorical as this is a multiclass classification problem\n","#Split to training and testing. Get a very small dataset for training as we will be \n","# fitting it to many potential models. \n","x_train_auto, x_test_auto, y_train_auto, y_test_auto = train_test_split(X, Y_cat, test_size=0.95, random_state=42)\n","\n","#Further split data into smaller size to get a small test dataset. \n","x_unused, x_valid, y_unused, y_valid = train_test_split(x_test_auto, y_test_auto, test_size=0.05, random_state=42)\n","\n","#Define classifier for autokeras. Here we check 3 different models, each model 25 epochs\n","clf = ak.ImageClassifier(max_trials=3) #MaxTrials - max. number of keras models to try\n","clf.fit(x_train_auto, y_train_auto, epochs=3)\n","\n","\n","#Evaluate the classifier on test data\n","_, acc = clf.evaluate(x_valid, y_valid)\n","print(\"Accuracy = \", (acc * 100.0), \"%\")\n","\n","# get the final best performing model\n","model = clf.export_model()\n","print(model.summary())\n","\n","#Save the model\n","model.save('cifar_model.h5')\n","\n","\n","score = model.evaluate(x_valid, y_valid)\n","print('Test accuracy:', score[1])\n","\"\"\""],"metadata":{"id":"M8P-evB8VYkq"},"execution_count":null,"outputs":[]}]}